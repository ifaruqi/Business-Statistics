---
title: "Business Statistics Mid-Term Assessment IB94X0 2022-2023 #1"
author: '2247946'
date: "2022-10-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE}
knitr::include_graphics("Warwick_Business_School_logo.svg")
```


# Masters Programmes
## Assignment Cover Sheet

---


Submitted by        : 2247946 <br>
Date Sent           : 2022-11-03			
Module Title        : Business Statistics		
Module Code         : IB94X0		
Date/Year of Module : Term One 2022-2023<br>
Submission Deadline : Wednesday, 3rd November 2022 (12:00 UK Time) 	
Word Count          :	Approximately (1500 words)
Number of Pages     : 1 HTML Pages		
Question            : Business Statistics (IB94X0) - Individual Assignment 1

<br>
“This is to certify that the work I am submitting is my own. All external references and sources are clearly acknowledged and identified within the contents. I am aware of the University of Warwick regulation concerning plagiarism and collusion.

No substantial part(s) of the work submitted here has also been submitted by me in other assessments for accredited courses of study, and I acknowledge that if this has been done an appropriate reduction in the mark I might otherwise have received will be made.”

<br>
“I declare that this work is entirely my own in accordance with the University's Regulation 11 and the WBS guidelines on plagiarism and collusion. All external references and sources are clearly acknowledged and identified within the contents. 

No substantial part(s) of the work submitted here has also been submitted by me in other assessments for accredited courses of study, and I acknowledge that if this has been done it may result in me being reported for self-plagiarism and an appropriate reduction in marks may be made when marking this piece of work.” 

---


# The Scenario

The dataset comes from the London Fire Brigade. A panel of Fire service managers and local politicians want to better understand some particular aspects of the costs and response times associated with incidents during the time period in the data.

Description of each variable are shown below.

Variable | Description
------------- | -------------
IncidentNumber | LFB unique identifier for the incident
DateOfCall | Date the 999 call for the incident was received by Brigade Control
TimeOfCall | Time the 999 call for the incident was received Brigade Control
IncidentGroup | High level description of the incident; Fire, Special Service or        False Alarm
StopCodeDescription | Stop code is an LFB short description of the type of incident attended (see PickLists)
SpecialServiceType | Special Services are emergencies other than Fire that the LFB attend. Special Service Type
PropertyCategory | A high level group to describe where the incident took place (see PickLists)
PropertyType |  more detailed description of where the incident took place (see PickLists)
AddressQualifier | This describes where the incident happened in relation to the address recorded
Postcode_full | The full postcode for the address recorded for the incident. This is withheld for incidents where
Postcode_district | The partial district postcode (eg SE1) for the address recorded for the incident.
WardCode | The Ward Code for the incident address recorded
WardName | The Ward Name for the incident address recorded
BoroughCode | The Borough Code for the incident address recorded
BoroughName | The Borough Code for the incident address recorded
Easting_m | The map easting coordinate for the incident location (to the nearest meter). This is withheld for incidents where the property category is Dwelling
Northing_m | The map northing coordinate for the incident location (to the nearest meter). This is withheld for incidents where the property category is Dwelling
Easting_rounded | The map easting representing the  centre of a 100x100m area where the incident occurred. This is used to provide granular information about the location of dwelling incidents but without making any singular incident uniquely identifiable.
Northing_rounded | The map northing representing the  centre of a 100x100m area where the incident occurred. This is used to provide granular information about the location of dwelling incidents but without making any singular incident uniquely identifiable.
FRS | The name of the Fire & Rescue Service area where the incident occurred; either London or the name of the neighbouring brigade where incident happen 'over-the-border'
IncidentStationGround | A description of the fire station area ("Ground") where the incident happened.
FirstPumpArriving_AttendanceTime | The attendance time (in seconds) for the first fire engine to arrive after it has been mobilised from a fire station (or other location if it was mobile by Brigade Control at the time of the call). When fire crews arrive they record their attendance using an on-board computer (a Mobile Data Terminal). There will be occasions when the first crew to arrive fail to record this correctly (either as human error or a delay/failure in the communications). When this happens the time recorded may in fact be the second or third.
FirstPumpArriving_DeployedFromStation | The fire station where the fire engine shown as being the first (the time in the above field) was sent from.
SecondPumpArriving_AttendanceTime | The attendance time (in seconds) for the second fire engine to arrive after it has been mobilised
SecondPumpArriving_DeployedFromStation | The fire station where the fire engine shown as being the second (the time in the above field) was sent from.
NumStationsWithPumpsAttending | The number of fire stations where fire engines were sent to support the incident. For large incidents this will include any stations involved in supplying additional and/or relief fire crews.
NumPumpsAttending | The total number of fire engines in attendance at the incident (excluding relief fire crews)
Notional Cost (£) | An estimate of the cost of the incident response

# The Request

This report fulfills the requests of the management board of London Fire Brigade, performing the specific analyses as follow:

  1. The total and average cost of responding to fires and false alarms
  2. The distribution of response times for all of incident group
  3. Summary of average response time for special service incidents
  4. A t-test comparing average response time in Ealing and Greenwich


# The Answer
The answer have two sections. 

The first section includes the code to perform all stages of the data analysis. This section could be shared with someone else who is not familiar with the data or project, but is an expert in R and statistics.

The second section is a polished and professional report presenting and interpreting the
findings for the panel of fire service managers and politicians.

***

# Section 1

## Initialization

```{r, message = FALSE}

# Install and load the necessary package and library

#install.packages("tidyverse")
#install.packages("grid")
#install.packages("gridExtra")
#install.packages("kableExtra")
#install.packages("Rmisc")
#install.packages("emmeans")
# install.packages("ggpubr")
library(tidyverse)
library(lubridate)
library(grid)
library(gridExtra)
library(kableExtra)
library(dplyr)
library(ggpubr)
library(emmeans)

options(width=100)
```

## Data Preparation

```{r, message=FALSE}

# read and load the fire data from the London Fire Brigade
firedata <- read_csv("London_Fire_data (2).csv")

# read and load data dictionary from the London Fire Brigade
datadict <- read_csv("DataDict.csv")

```

```{r, include = TRUE, results = "hide"}

# check the summary of the data
summary(firedata)

# check the structure of the data
str(firedata)

```
  
```{r, include = TRUE, results = "hide"}

# Changing Column Name for Convenience
colnames(firedata)[which(names(firedata) == "Notional Cost (£)")] <- "IncidentCost"

# Change DateofCall column into Date date type
firedata$DateOfCall <- as.Date(lubridate::dmy(firedata$DateOfCall))

# Create a new column to indicate the month when incident happens
firedata$MonthOfCall <- as.Date(cut(firedata$DateOfCall, breaks = "month"))

# Change data types for CalYear and IncidentGroup columns
# First generate a vector to keep the column names
columns <- c("CalYear", "IncidentGroup")

# Then, set the correct data types for the defined columns
firedata[columns] <- lapply(firedata[columns], factor)

# To check the new structure of the data after several changes above
str(firedata)

```

The data is now ready to be used for the analysis.

## 1. The Costs of Responding to Fires and False Alarms

**Total & Average Cost of Fire and False Alarm Incident**

```{r}
# Create a subset of data to exclude Special Service data
firedata_without_specialservice <- filter(firedata, IncidentGroup != "Special Service")

# Create a summary of Fire and False Alarm Incident
firedata_without_specialservice_summary <- firedata_without_specialservice %>% 
  group_by(IncidentGroup) %>% 
  summarise( "TotalCost" = round(sum(IncidentCost/1000000, na.rm = TRUE),2), 
             "AverageCost" = round(mean(IncidentCost, na.rm = TRUE),2) )

# Add a new column to store a label for the graph
firedata_without_specialservice_summary$'Total Cost' <-
  paste(paste("£",as.character(round(firedata_without_specialservice_summary$TotalCost,1)),"M"))

firedata_without_specialservice_summary$'Average Cost' <-
  paste("£",as.character(round(firedata_without_specialservice_summary$AverageCost,1)))

# Print the requested information
print(firedata_without_specialservice_summary)

```


**Visualization of Yearly Cost of Fire and False Alarm Incidents**

```{r, message = FALSE, warning = FALSE}
# Create subset of dataset to group the data based on year 
total_cost_per_year <- firedata_without_specialservice %>% 
  group_by(CalYear) %>% 
  summarise("Number of Incident" = n(), "Cost" = sum(IncidentCost/1000000, na.rm = TRUE) )

total_cost_per_year$TotalCost <- paste(paste("£",as.character(round(total_cost_per_year$Cost,1)),"M"))

# Create subset of dataset to group the data based on year and incident group
total_cost_group <- firedata_without_specialservice %>% 
  group_by(CalYear, IncidentGroup) %>% 
  summarise("Incident" = n(), "Cost" = sum(IncidentCost/1000000, na.rm = TRUE))

# Create a new column to save the label for the bar plot
total_cost_group$costlabel <- paste(paste("£",as.character(round(total_cost_group$Cost,1)),"M"))


# Plot a bar chart to visualise total cost of Fire and False Alarm incidents
ggplot(total_cost_group, aes(x = CalYear , y = Cost, fill = IncidentGroup, label = costlabel))+
  annotate("text", x = total_cost_per_year$CalYear, y = total_cost_per_year$Cost+2, 
           label = total_cost_per_year$TotalCost)+
  geom_bar(stat = "identity", width = 0.5) +
  geom_text(size = 2.5, position = position_stack(vjust= 0.5))+

  ggtitle("Total Cost of Fire and False Alarm Incidents per Year") +
  labs(x = "Calendar Year", y = "Incident Cost", caption = "*until January 2022")+
  ylim(0,40)+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5))+ 
  theme(title = element_text(face="bold"))+
  theme(legend.position = "right")+
  scale_fill_discrete(name = "Incident Group")+
  theme(legend.key.size = unit(0.2, 'cm'))
  
```

The chart shows that in the last three years the total cost for responding to False Alarm is always greater than the cost for responding to actual fire incidents.

**Visualization of Monthly Cost Average of Fire and False Alarm Incidents**

```{r, message = FALSE, warning = FALSE}
# Create a subset of data for Monthly Average Cost  
total_cost_per_month <- firedata_without_specialservice %>% 
  group_by(MonthOfCall, IncidentGroup) %>% 
  summarise("Number of Incident" = n(), 
            "Cost" = sum(IncidentCost/1000000, na.rm = TRUE),
            "AverageCost" = mean(IncidentCost, na.rm = TRUE))

# Create variable for Average Respon Time of Fire and False Alarm Incident
mean_responsetime_fire <- round(mean(firedata_without_specialservice$IncidentCost[firedata_without_specialservice$IncidentGroup == "Fire"], na.rm = TRUE))

mean_responsetime_falsealarm <- round(mean(firedata_without_specialservice$IncidentCost[firedata_without_specialservice$IncidentGroup == "False Alarm"], na.rm = TRUE))

mean_responsetime <- c(mean_responsetime_fire, mean_responsetime_falsealarm)


# Creating subset of dataset to group the data based on Type of Incident
mean_cost_group <- firedata_without_specialservice %>% 
  group_by(IncidentGroup) %>% 
  summarise("Incident" = n(), 
            "Cost" = round(sum(IncidentCost/1000000, na.rm = TRUE)),
            "AverageCost" = round(mean(IncidentCost, na.rm = TRUE)))

# Creating a new column to save the label for the line plot
mean_cost_group$costlabel <- paste("mean = £",
                                         as.character(mean_cost_group$AverageCost))

mean_cost_group$datelabel <- as.Date(c("2021-10-01","2021-10-01"))

# Create a plot to illustrate monthly average cost of Fire and False Alarm Incident
ggplot(total_cost_per_month, aes(x = MonthOfCall, y = AverageCost, color = IncidentGroup))+
  geom_line(size = 1)+
  geom_hline(yintercept = mean_cost_group$AverageCost, size = 0.5, 
             linetype = "dashed", col = c("#F8766D","#00BA38"))+
  geom_text(data = mean_cost_group,aes(datelabel, AverageCost +c(125,200),label = costlabel, vjust = 1),
            size = 2.5, show.legend = FALSE)+
  ggtitle("Average Cost of Fire and False Alarm Incident per Month") +
  labs(x = "Month", y = "Average of Incident Cost (£)", color = "Incident Group")+
  ylim(0,1200)+
  theme_classic()+
  scale_x_date(date_labels = "%b-%y", breaks = "2 month")+
  theme(plot.title = element_text(hjust = 0.5))+ 
  theme(title = element_text(face="bold"))+
  theme(legend.position = "right")+
  scale_fill_discrete(name = "Incident Group")+
  theme(legend.key.size = unit(0.5, 'cm'))+
  theme(axis.text.x = element_text(size=10, angle=90))

# Create a plot to illustrate monthly total cost of Fire and False Alarm Incident
ggplot(total_cost_per_month, aes(x = MonthOfCall, y = Cost, color = IncidentGroup))+
  geom_line(size = 1)+
  geom_hline(yintercept = mean_cost_group$TotalCost, size = 0.5, 
             linetype = "dashed", col = c("#F8766D","#00BA38"))+
  ggtitle("Total Cost of Fire and False Alarm Incident per Month") +
  labs(x = "Month", y = "Total of Cost (M£)", color = "Incident Group")+
  ylim(0,2.5)+
  theme_classic()+
  scale_x_date(date_labels = "%b-%y", breaks = "2 month")+
  theme(plot.title = element_text(hjust = 0.5))+ 
  theme(title = element_text(face="bold"))+
  theme(legend.position = "right")+
  scale_fill_discrete(name = "Incident Group")+
  theme(legend.key.size = unit(0.5, 'cm'))+
  theme(axis.text.x = element_text(size=10, angle=90))
  
```

A seasonality trend can be seen (although not so obvious) that the total cost for fire incidents increase during summer time compared to winter period.

The average cost of Fire incidents fluctuates throughout the months but always higher than the average cost for False Alarm which tend to have similar average cost throughout the months.


**Plotting The Distribution of Incident Cost**

```{r, message = FALSE, warning = FALSE}
ggplot(firedata_without_specialservice, aes(IncidentCost))+
  geom_histogram()+
  labs(x = "Incident Cost (£)", y= "Frequency")+
  ggtitle("Distribution of Incident Cost")+
  theme(plot.title = element_text(hjust = 0.5))+ 
  theme(title = element_text(face="bold"))

```
The distribution looks heavily skewed. Further analysis is performed below to decide whether the outliers should be removed or not.

**Relationship Between Pump Hours and Incident Cost**

```{r, message = FALSE, warning = FALSE}
ggplot(firedata_without_specialservice, aes(x = PumpHoursRoundUp, y = IncidentCost))+
  geom_point()+
  geom_smooth(method = lm)+
  facet_grid(IncidentGroup ~., scales = "free")+
  labs(x = "Pump Hours (h)", y= "Incident Cost (£)")+
  ggtitle("Relationship between Pump Hours and Incident Cost")+
  theme_linedraw()+
  theme(plot.title = element_text(hjust = 0.5))+ 
  theme(title = element_text(face="bold"))
```
The graph shows that the incident cost is positively correlated with duration of pumping during the incidents. This plot could be the basis of not performing data cleaning on the extremely costly incident. The huge cost is incurred due to the rare incidents which require way longer pumping duration.

Other factors contribute to the cost are not examined in this file. 

## 2. The Distribution of of Response Time

**Visualization of Response Time for All Incidents**
```{r, message = FALSE, warning = FALSE}

# Create label for the plot
ResponseTimeLabel <- 
  paste("Mean =", as.character(round(mean(firedata$FirstPumpArriving_AttendanceTime, na.rm=TRUE))),"Seconds")

# Save the mean of Response Time to a variable 
ResponseTimeMean <-
  round(mean(firedata$FirstPumpArriving_AttendanceTime, na.rm=TRUE))

# Plot the distribution of response time with frequency as y axis
responsetime_freqplot <- ggplot(data = firedata)+
  geom_histogram(aes(x=FirstPumpArriving_AttendanceTime,), binwidth = 30, color="black")+
  geom_density(aes(x=FirstPumpArriving_AttendanceTime), fill = "red", alpha = 0.2)+
  geom_vline(aes(xintercept = mean(FirstPumpArriving_AttendanceTime, na.rm = TRUE)), col = "green")+
  annotate("text", x = ResponseTimeMean + 200,label= ResponseTimeLabel, y=50000, col="green")+
  ggtitle("Distribution of Response Time for All Incidents")+
  labs(x = "Response Time (s)", y = "Frequency")+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(title = element_text(face="bold"))

plot(responsetime_freqplot)

# Plot the distribution of response time with density as y axis
responsetime_densplot <- ggplot(data = firedata)+
  geom_histogram( mapping = (aes(x=FirstPumpArriving_AttendanceTime, y = ..density..)),binwidth = 30,color="black")+
  geom_density(aes(x=FirstPumpArriving_AttendanceTime), fill = "red", alpha = 0.2)+
  geom_vline(aes(xintercept = mean(FirstPumpArriving_AttendanceTime, na.rm = TRUE)), col = "green")+
  annotate("text", x = ResponseTimeMean + 200,label= ResponseTimeLabel, y=0.004, col="green")+
  ggtitle("Distribution of Overall Response Time")+
  labs(x = "Response Time (s)", y = "Density")+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(title = element_text(face="bold"))

plot(responsetime_densplot)

```

**Summary of Average Response Time Per Incident Group**

```{r}
# Create a summary of Response Time data
mean_response_time <- firedata %>% 
  group_by(IncidentGroup) %>% 
  summarise("Incident" = n(), 
            "ResponseTime" = mean(FirstPumpArriving_AttendanceTime, na.rm = TRUE))

# Creating a new column to save the label for the vline
mean_response_time$'ResponseLabel' <- paste(as.character(round(mean_response_time$ResponseTime)),"Seconds")



# Print the requested information in a proper table format
mean_response_time[,c("IncidentGroup", "ResponseLabel")] %>%
  kbl(col.names = c("Incident Group", "Average Response Time"),
      caption = "Table 2. Summary of Average Response Time for Each Incident Group") %>%
  kable_styling()
  
```

The average response time for each incident group are similar to each other. The deviation from the mean for all incidents is not that big (plus-minus 10 seconds).

**Visualization of Average Response Time Per Incident Group** 

```{r, message = FALSE, warning = FALSE}
# Frequency Plot
responsetime_group_freqplot <- ggplot(data = firedata)+
  geom_histogram(mapping = (aes(x=FirstPumpArriving_AttendanceTime, fill = IncidentGroup,)), color="black")+
  geom_vline(data = mean_response_time,aes(xintercept = ResponseTime), col = "red", size = 1)+
  geom_text(data = mean_response_time,aes(x=ResponseTime + 300, label=ResponseLabel,
                                          y=20000),colour="black")+
  #ggtitle("Distribution of Response Time for Each Incident Group")+
  labs(x = "Response Time (s)", y = "Frequency")+
  facet_grid(IncidentGroup ~.)+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(title = element_text(face="bold"))+
  theme(legend.position = "none")

plot(responsetime_group_freqplot)

# Density Plot
responsetime_group_densplot <- ggplot(data = firedata)+
  geom_histogram(mapping = (aes(x=FirstPumpArriving_AttendanceTime, y = ..density..,  
                                fill = IncidentGroup,)), color="black")+
  geom_density(aes(x=FirstPumpArriving_AttendanceTime), fill = "red", alpha = 0)+
  geom_vline(data = mean_response_time, aes(xintercept = ResponseTime), col = "red", size = 1)+
  geom_text(data = mean_response_time, aes(x=ResponseTime + 300, label=ResponseLabel, 
                                           y=0.003), colour = "red")+
  #ggtitle("Distribution of Response Time for Each Incident Group")+
  labs(x = "Response Time (s)", y = "Density")+
  facet_grid(IncidentGroup ~.)+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(title = element_text(face="bold"))+
  theme(legend.position = "none")

plot(responsetime_group_densplot)

```

Distribution in the density graph of all the three graph is similar, but the frequency is different. Fire incident is least frequent to happen.

## 3. Summary of Special Service Response Times

**Summary of Special Service Response Time Data**

```{r}
# Creating data frame for Special Service Incidents
special_service_data <- firedata %>% 
  filter(IncidentGroup == 'Special Service')

```
**Preparation for Distribution of Response Time Plot**

```{r}
# Calculate Average Response Time for Special Service Incident
ss_response_time_mean <-
  round(mean(special_service_data$FirstPumpArriving_AttendanceTime, na.rm = TRUE))
ss_response_time_label <-
  paste("Mean: ",paste(round(mean(special_service_data$FirstPumpArriving_AttendanceTime, na.rm = TRUE)), "s"))

# Calculate 10th Percentile of Response Time for Special Service Incident
ss_response_time_10th <-
  round(quantile(special_service_data$FirstPumpArriving_AttendanceTime, probs= 0.1, na.rm = TRUE))
ss_response_time_10_th_label <-
  paste("10th Percentile:",paste(round(quantile(special_service_data$FirstPumpArriving_AttendanceTime, probs= 0.1, na.rm = TRUE)), "s"))

# Calculate 90th Percentile of Response Time for Special Service Incident
ss_response_time_90th <-
  round(quantile(special_service_data$FirstPumpArriving_AttendanceTime, probs= 0.9, na.rm = TRUE))
ss_response_time_90_th_label <-
  paste("90th Percentile: ",paste(round(quantile(special_service_data$FirstPumpArriving_AttendanceTime, probs= 0.9, na.rm = TRUE)), "s"))

# Create a data frame to create multiple vertical line in histogram (as annotation)
ss_line_value <- c(ss_response_time_10th, ss_response_time_mean, ss_response_time_90th)
ss_line_color <- c("red", "green", "blue")
ss_line_label <-c(ss_response_time_10_th_label, ss_response_time_label, ss_response_time_90_th_label)
multi_vline <- data.frame(ss_line_value, ss_line_color, ss_line_label)


```

**Visualization of Distribution of Response Time of Special Service Incident**

```{r, message = FALSE, warning = FALSE}
# Plot the distribution of Response Time for Special Service Incident
ggplot(data = special_service_data)+
  geom_density(aes(x=FirstPumpArriving_AttendanceTime), fill = "red", alpha = 0.2)+
  geom_vline(data = multi_vline, aes(xintercept = ss_line_value), col = ss_line_color)+
  geom_text(data = multi_vline, 
            aes(x=ss_line_value + c(-120,70,120), label=ss_line_label, y=0.005), 
            col = ss_line_color, size = 2.5)+
  ggtitle("Distribution of Response Time to Special Service Incidents")+
  labs(x = "Response Time (Second)", y = "Density")+
  scale_x_continuous(limits = c(0,1300),breaks=c(0, 174, 318, 480, 750, 1250))+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(title = element_text(face="bold"))

```

**ECDF Plot**
```{r}
ggplot(special_service_data, aes(FirstPumpArriving_AttendanceTime))+
  stat_ecdf(geom = "step", na.rm = TRUE, pad = FALSE)+
  geom_segment(aes(x = -Inf, y = 0.1, xend = 174, yend = 0.1), linetype = "dashed", col = "red")+
  geom_segment(aes(x = 174, y = -Inf, xend = 174, yend = 0.1), linetype = "dashed", col = "red")+
  geom_segment(aes(x = -Inf, y = 0.55, xend = 318, yend = 0.55), linetype = "dashed", col = "green")+
  geom_segment(aes(x = 318, y = -Inf, xend = 318, yend = 0.55), linetype = "dashed", col = "green")+
  geom_segment(aes(x = -Inf, y = 0.9, xend = 480, yend = 0.9), linetype = "dashed", col = "blue")+
  geom_segment(aes(x = 480, y = -Inf, xend = 480, yend = 0.9), linetype = "dashed", col = "blue")+
  annotate("text", x = c(30,12,30),y = c(0.08,0.53,0.88), 
           label = c("10th Percentile", "Mean", "90th Percentile"), 
           col = c("red", "green", "blue"),
           size = 2.5)+
  ggtitle("Empirical Cumulative Distribution Function of Response Time",
          subtitle = "Special Service Incident")+
  scale_x_continuous(limits = c(0,1300),breaks=c(0, 174, 318, 480, 750, 1250))+
  scale_y_continuous(limits = c(0,1),breaks=c(0, 0.1, 0.55, 0.9, 1))+
  labs(x = "Response Time (s)", y = "F (Response Time)")+
  theme_classic()+
  theme(title = element_text(face="bold"))

```

As the distribution of Response Time fot Special Service incidents is slightly positively skewed, the means sits at 55th percentile. It means that the means is greater than 55% of the data.

**Summary of Average Response time for each Special Service Type**

```{r}
# Create a summary of mean, 10th percentile and 90th percentile of response time for each Special Service Type
special_service_summary <-special_service_data %>% 
  filter(is.na(SpecialServiceType)==FALSE) %>%
  group_by(SpecialServiceType) %>% 
  summarise("Frequency" = n(), 
            "MeanResponseTime" = round(mean(FirstPumpArriving_AttendanceTime, na.rm = TRUE)),
            "Percentile10_ResponseTime" = round(quantile(FirstPumpArriving_AttendanceTime, probs = 0.1, 
                                               na.rm = TRUE)),
            "Percentile90_ResponseTime" = round(quantile(FirstPumpArriving_AttendanceTime, probs = 0.9, 
                                         na.rm = TRUE)),
            "MaxResponseTime" = round(max(FirstPumpArriving_AttendanceTime, na.rm = TRUE),2),
            "MinResponseTime" = round(min(FirstPumpArriving_AttendanceTime, na.rm = TRUE),2)
            ) 

# Removing NA values
special_service_data <- special_service_data[!is.na(special_service_data$SpecialServiceType),]

# Arrange based on mean value
special_service_summary <- special_service_summary %>% 
  arrange(desc(MeanResponseTime))

# Print the requested information in a proper table format
print(special_service_summary)

```

**Visualization of Average Response time for each Special Service Type**

```{r}
ggplot(special_service_summary, aes(x=reorder(SpecialServiceType, -MeanResponseTime),
                                    y=MeanResponseTime)) + 
  geom_point() + 
  geom_crossbar(aes(ymin = Percentile10_ResponseTime, ymax = Percentile90_ResponseTime), width = 0.5)+
  geom_errorbar(aes(ymin = MinResponseTime, ymax = MaxResponseTime), width = 0.5)+
  ggtitle("Distribution of Response Time for Each Type of Special Service Incident")+
  labs(y="Response Time (s)", x="Special Service Type")+ 
  ylim(0,1200)+
  theme_classic()+
  theme(axis.text.x = element_text(size=10, angle=90))+
  theme(plot.title = element_text(hjust = 0))+
  theme(title = element_text(face="bold"))
 
```
Note that in the graph above, the upper and lower boundary of the box represent 90th and 10th percentile respectively (instead of the standar 75th percentile and 25th percentile).

Based on the table above, I suspect that the values for Water Provision, Medical Incident, and Removal of Object from People are outlier as suggested in the histogram chart below.

**Distribution of Average Response time for each Special Service Type**

```{r}
# Plot distribution of the mean value of each Special Service Type
ggplot(special_service_summary, aes(MeanResponseTime))+
  geom_histogram(binwidth = 10)+
  labs(x = "Response Time (s)", y = "Frequency")+
  ggtitle("Distribution of Average Response Time for Each Special Service Incident")+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(title = element_text(face="bold"))
```

## 4. A t-test Comparing Ealing and Greenwich

An independent samples $t$-test is for testing the difference between two independent groups

$t = \frac{(\bar{x}_1-\bar{x}_2)-(\mu_1-\mu_2)}{s_{\bar{x}_1-\bar{x}_2}}   = \frac{\bar{x}_1-\bar{x}_2}{\sqrt{\frac{s_1^2}{n_1}+\frac{s^2_2}{n_2}}}$

Symbol | Description
------ | ----------------------
$\bar{x}_i$ | The mean of the sample $i$
$s_{\bar{x}_1-\bar{x}_2}$ | The standard error of the difference in sample means
$s_i$ | The standard deviation of sample $i$
$n_i$ | The number of observations in the sample $i$



**Creating a subset of data**

```{r}
# Filtering Ealing & Greenwich data
EalingGreenwich <- firedata %>% 
  filter(ProperCase %in% c("Ealing", "Greenwich"))
```

**Calculate Simple Statistical Summary**

```{r}
EalingGreenwich_summary <- EalingGreenwich %>% 
 	group_by(ProperCase) %>% 
	summarise("Average of Response Time" = round(mean(FirstPumpArriving_AttendanceTime, na.rm = TRUE)), 
	          "Standard Deviation of Response Time" = sd(FirstPumpArriving_AttendanceTime, na.rm=TRUE), 
	          "Frequency" = n()) 

# Change the column name to be use as legend title
colnames(EalingGreenwich_summary)[which(names(EalingGreenwich_summary) == "ProperCase")] <- "Area"


# Print the requested information
print(EalingGreenwich_summary)

```

**Plot Distribution of Response Time between Ealing and Greenwich**

```{r, warning = FALSE, message = FALSE}
ggplot(EalingGreenwich, aes(FirstPumpArriving_AttendanceTime,..density.., fill=ProperCase))+
  geom_histogram(binwidth=30,position="identity", alpha=0.5)+ 
  labs(x="Response Time (s)", y="Density", fill="Area")+
  ggtitle("Distribution of Response Time for Ealing and Greenwich Area")+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(title = element_text(face="bold"))
  
```

**Performing t-test**

```{r}
t.test(FirstPumpArriving_AttendanceTime ~ ProperCase, data = EalingGreenwich)
```

Note that Welch Two Sample t-test is used. P-value obtained from the t-test suggest that null hypothesis can be rejected and therefore there is a significant difference of average response time between Ealing and Greenwich.


**Estimation Approach**
```{r}
ResponseTime_by_Location <- lm(FirstPumpArriving_AttendanceTime ~ ProperCase, data = EalingGreenwich)
(ResponseTime_by_Location_Emm <- emmeans(ResponseTime_by_Location, ~ProperCase))
(ResponseTime_by_Location_Contrast <- confint(pairs(ResponseTime_by_Location_Emm)))  

```

**Visualization of Estimation Approach**

```{r}
# Plot Estimated Average Response Time in Ealing and Greenwich
EalingGreenwich_Plot <- 
  ggplot(summary(ResponseTime_by_Location_Emm), aes(x=ProperCase, y=emmean, ymin=lower.CL, ymax=upper.CL)) +
  geom_point() + 
  geom_linerange() + 
  labs(y="Response Time (s)", x="Area", subtitle="Error bars are 95% CIs",
		     title="Response Time in Ealing and Greenwich")+
  scale_y_continuous(breaks = c(309, 311, 314, 317, 320))+
  theme(title = element_text(face="bold", size = 6))

# Plot Estimated Difference of Average Response Time between Ealing and Greenwich
EalingGreenwich_difference_Plot <-
  ggplot(ResponseTime_by_Location_Contrast, aes(x=contrast, y=estimate, ymin=lower.CL, ymax=upper.CL)) +
  geom_point() + 
  geom_linerange() + 
  labs(y="Difference of Response Time (s)", x="Area", subtitle="Error bars are 95% CIs",
       title="Difference of Response Time between Ealing and Greenwich") + 
  scale_y_continuous(breaks = c(0, 1.73, 5.5, 9.38))+
  geom_hline(yintercept=0, lty=2)+
  theme(title = element_text(face="bold", size = 6))

# Arrange both plot into a single plot
grid.arrange(EalingGreenwich_Plot, EalingGreenwich_difference_Plot, ncol = 2)
```


# Section 2

## 1. The Costs of Responding to Fires and False Alarms

After processing the data provided by London Fire Brigade, the total cost and average cost of Fire and False Alarm incidents are summarised in the table 1. below.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
# Print the requested information in a proper table format
firedata_without_specialservice_summary[,c("IncidentGroup", "Total Cost", "Average Cost")] %>%
  kbl(col.names = c("Incident Group", "Total Cost", "Average Cost"),
      caption = "Table 1. Summary of Fire and False Alarm Cost for 2019-2022") %>%
  kable_styling()
```

Based on the data summarised in the Table 1 above, it is clear that False Alarm costs ($£\ 61.2 \ M$) more than actual Fire Incident ($£\ 43.1\ M$) during the time period. However, the table also shows that the average cost of Fire Incident($£\ 838$) is more than twice of Average False Alarm cost($£\ 378.4$) during the same time frame. This indicates that False Alarm incidents are more frequent to happen compared to the actual Fire incidents. 

Preventing and identifying false alarm incidents could be the area of improvement that the London Fire Brigade might look at. While the average cost of False Alarm incidents might be small but its high frequency makes the total cost become significantly higher than Fire incidents. This statement is supported by the consistent trend of Fire and False Alarm total cost from 2019 to 2021. Each year, False Alarm always has bigger total cost and smaller average cost than the actual Fire Incident.


## 2. The Distribution of of Response Time

The distribution of response time for all of the incident is shown in the figure 1 below

```{r, echo = FALSE, warning = FALSE, message = FALSE}
plot(responsetime_densplot)
```
<center>**Figure 1. Distribution of Response Time for All Incident Group**</center>

As shown in Figure 1, the distribution of response time for all incidents is slightly positively skewed (skew to the right). It means that there are several incident that has way longer response time than most of the other incidents. For all of the incidents recorded during the time period, the average response time is $308$ seconds. 

To better understand the response time of each incident group, figures showing the distribution of response time for each incident group are prepared below


```{r, echo = FALSE, warning = FALSE, message = FALSE}
# Plot the distribution of response time for each incident group
grid.arrange(responsetime_group_densplot, responsetime_group_freqplot, ncol = 2, 
             top = text_grob("Distribution of Response Time for Each Incident Group", size = 15, face = "bold"))
```
<center>**Figure 2. Distribution of Response Time for Each Incident Group**</center>

Figure 2 shows that Special Service and Fire incidents have longer average response time ($319 \ s$ and $318 \ s$ respectively) than the average response time for all incidents. On the other hand, False Alarm has approximately **6%** faster response time ($299 \ s$) than the average response time for all incidents. 

The density plot of each incident group has relatively similar shape with each other. It means that the response time and the distribution of the response in each group also similar with each other. However, from the frequency chart in Figure 2, it can be inferred that the False Alarm is the most frequent incident to happen, followed by Special Service and Fire incident respectively.


## 3. Summary of Special Service Response Times

The breakdown of the average response time for each type of Special Service incident is provided in the table 2. Along with the average response time, the $10^{th}$ percentile and $90^{th}$ percentile response time along with the frequency of the incidents are also included in the table.

In the table, the type of incident that has greater average response time than the average response time of overall special service incident are written in red.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
special_service_summary[,c("SpecialServiceType", 
              "Frequency",
              "MeanResponseTime",
              "Percentile10_ResponseTime",
              "Percentile90_ResponseTime")]%>%
  kbl(col.names = c("Special Service Type", "Total Incident", "Average Response Time (s)",
                    "10th Percentile of Response Time (s)","90th Percentile of Response Time (s)"),
      caption = "Table 2. Response Time for Special Service Incident") %>%
  kable_styling() %>% 
  row_spec(which(special_service_summary$MeanResponseTime > 318), bold = T, color = "red", background = "white") %>% 
  row_spec(which(special_service_summary$MeanResponseTime < 250), bold = T, color = "black", background = "orange")
```

Generally, special service type that has longer average response time than the overall Special Service average response time also has longer $10th$ percentile and $90th$ percentile response time.

**'Spills and Leaks (not RTC)'** is the incident that has the longest average response time with $350$ seconds ($32$ seconds longer than the average response time for all special service incident). Among the incident type that has greater average response time than the overall response time, **'Flooding'** with the average response of $328$ seconds, is the type of incident that occurs the most ($22,853$ incidents) during the period.

Three type of incidents at the bottom of the table are worth to be highlighted. First, **'Water provision'** incident type has only 1 record. So the number of average response time, $10^{th}$ percentile response time and $90^{th}$  percentile response time in the table might not be able to represent the response time of **'Water provision'** incidents. Second, **'Medical incident'** and **'Removal of objects from people** have extremely low $10^{th}$ percentile response time with 8 seconds and 7 seconds respectively. These values must be further investigated before taking any conclusion because those values looks like outliers.


## 4. A t-test Comparing Ealing and Greenwich

The average response time for incident happens in Ealing and Greenwich are compared to see whether the average response time in one area is longer than the other. 

A table comparing the average response time for incident in Ealing and Greenwich is prepared below.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
EalingGreenwich_summary %>%
  kbl(caption = "Table 3. Average of Response Time in Ealing and Greenwich") %>%
  kable_styling()
```

Based on the result above, Null Hypothesis Significance Testing (NHST) and Estimation Approach are used to test the significance of the difference between the average response time in Ealing and Greenwich.

**Null Hypothesis Significance Testing (NHST)**

In NHST method, t-test is used. A t-test is a statistical test that compares the means of two samples. In a two sample t-test, the null hypothesis is the means difference between two samples equal to zero. On the opposite, the alternate hypothesis is that the means difference between two sample is not equal to zero.

A two sample t-test was performed to compare average response time (in seconds) between Ealing and Greenwich; $t(19303) = 2.9$, $p<0.0043$.

The result of the t-test shows that the $p-value$ is less then 0.005 ($p-value < 0.005$), therefore Null Hypothesis can be rejected. It can be concluded that there is a significant difference in average response time between Ealing (Mean = 317, SD = 138) and Greenwich (Mean = 311, SD = 133)

**Estimation Approach**

Rather than using one value to determine the significance difference of two means, estimation method introduce the concept of Confidence Interval (CI) to supplement the point estimate (in this case average response time) with information about the uncertainty in this estimate.

After performing estimation approach, the result is obtained. The average response time in Ealing is $317$ seconds 95% CI [314, 320] and the average response time in Greenwich is $311$ seconds 95% CI [309, 314]. The average response is $5.5$ seconds 95% CI [1.73, 9.38] longer in Ealing compared to Greenwich.

The result can be incorporated in a graph as follow.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
grid.arrange(EalingGreenwich_Plot, EalingGreenwich_difference_Plot, ncol = 2)
```
<center>**Figure 3. Comparison of Average Response Time between Ealing and Greenwich**</center>

On the left is a graph comparing estimated average response time (black dot) for each area along with the 95% confidence interval (black line). On the right is a graph showing the estimated difference of average response time between Ealing and Greenwich (black dot) along with its 95% confidence interval. The fact that the lower bound of the confidence interval of the graph on the right does not intersect $y = 0$ line means that with 95% CI, the mean difference of average response time between Ealing and Greenwich is not equal to zero but rather falls in between $1.73$ and $9.38$ interval with the most likely estimation would be $5.5$ seconds.

